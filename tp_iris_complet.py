# TP N¬∞ 1: Classification des fleurs iris avec un mod√®le d'apprentissage automatique simple
# Code complet - Toutes les √©tapes

# ========== IMPORTATION DES BIBLIOTH√àQUES ==========
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle

# ========== √âTAPE 1 & 2 : CHARGEMENT ET EXPLORATION DES DONN√âES ==========
print("="*60)
print("√âTAPE 1 & 2 : CHARGEMENT ET EXPLORATION DES DONN√âES")
print("="*60)

df = pd.read_csv("Iris.csv", sep=";")

# Afficher les premi√®res lignes du jeu de donn√©es
print("\nPremi√®res lignes du dataset :")
print(df.head())
print("\nColonnes originales :")
print(df.columns)

# Normaliser les noms des colonnes en minuscules et sans espaces
df.columns = [col.strip().lower().replace(" ", "_") for col in df.columns]
print("\nColonnes apr√®s normalisation :")
print(df.columns.tolist())

# Statistiques descriptives pour comprendre la distribution des caract√©ristiques
print("\nStatistiques descriptives :")
print(df.describe())

# Visualisation de la r√©partition des classes
plt.figure(figsize=(8, 5))
sns.countplot(x='species', data=df)
plt.title('Distribution des esp√®ces d\'iris')
plt.savefig('distribution_species_initial.png')
plt.show()

# ========== EXERCICE 1 : EFFECTIFS ET REPR√âSENTATIONS GRAPHIQUES ==========
print("\n" + "="*60)
print("EXERCICE 1 : EFFECTIFS ET REPR√âSENTATIONS GRAPHIQUES")
print("="*60)

# 1- Afficher l'effectif de chaque esp√®ce dans le jeu de donn√©es
effectifs = df['species'].value_counts()
print("\nEffectifs par esp√®ce :")
print(effectifs)

# 2- Repr√©sentations graphiques

# a) Histogramme des esp√®ces
plt.figure(figsize=(8, 5))
effectifs.plot(kind='bar')
plt.title("Histogramme des esp√®ces")
plt.xlabel("Esp√®ces")
plt.ylabel("Effectif")
plt.savefig('ex1_histogramme.png')
plt.show()

# b) Diagramme circulaire des esp√®ces
plt.figure(figsize=(8, 8))
effectifs.plot(kind='pie', autopct='%1.1f%%')
plt.title("R√©partition des esp√®ces")
plt.ylabel("")
plt.savefig('ex1_pie.png')
plt.show()

# c) Barres group√©es
plt.figure(figsize=(8, 5))
plt.bar(effectifs.index, effectifs.values)
plt.title("Barres group√©es des esp√®ces")
plt.xlabel("Esp√®ces")
plt.ylabel("Effectif")
plt.savefig('ex1_barres_groupees.png')
plt.show()

# d) Diagramme en cascades
plt.figure(figsize=(8, 5))
values = effectifs.values
cum = np.cumsum(values)
plt.bar(effectifs.index, values)
plt.plot(effectifs.index, cum, marker='o', color='red', linewidth=2)
plt.title("Diagramme en cascade des esp√®ces")
plt.ylabel("Effectif cumul√©")
plt.savefig('ex1_cascade.png')
plt.show()

# 3- Choix des colorations
plt.figure(figsize=(8, 5))
effectifs.plot(
    kind='bar',
    color=['green', 'orange', 'blue']
)
plt.title("Effectifs par esp√®ce (color√©)")
plt.xlabel("Esp√®ce")
plt.ylabel("Nombre d'observations")
plt.savefig('ex1_colore.png')
plt.show()

print("\n‚úÖ Exercice 1 termin√© - Meilleure repr√©sentation : histogramme ou diagramme circulaire")

# ========== EXERCICE 2 : VARIABLES QUANTITATIVES ==========
print("\n" + "="*60)
print("EXERCICE 2 : ANALYSE DES VARIABLES QUANTITATIVES")
print("="*60)

# 1- R√©sum√© de la variable 'Petal.Length'
print("\nR√©sum√© de 'petallength' :")
print(df['petallength'].describe())

# 2- Visualisation de la variable 'Petal.Length' par un histogramme
plt.figure(figsize=(8, 5))
plt.hist(df['petallength'], bins=10, edgecolor='black')
plt.title("Histogramme de la longueur du p√©tale")
plt.xlabel("Longueur du p√©tale (cm)")
plt.ylabel("Effectif")
plt.savefig('ex2_petal_length.png')
plt.show()

# 3- M√™me analyse pour les autres variables num√©riques

# a) SepalLength
print("\nR√©sum√© de 'sepallength' :")
print(df['sepallength'].describe())

plt.figure(figsize=(8, 5))
plt.hist(df['sepallength'], bins=10, edgecolor='black')
plt.title("Histogramme de la longueur du s√©pale")
plt.xlabel("Longueur du s√©pale (cm)")
plt.ylabel("Effectif")
plt.savefig('ex2_sepal_length.png')
plt.show()

# b) SepalWidth
print("\nR√©sum√© de 'sepalwidth' :")
print(df['sepalwidth'].describe())

plt.figure(figsize=(8, 5))
plt.hist(df['sepalwidth'], bins=10, edgecolor='black')
plt.title("Histogramme de la largeur du s√©pale")
plt.xlabel("Largeur du s√©pale (cm)")
plt.ylabel("Effectif")
plt.savefig('ex2_sepal_width.png')
plt.show()

# c) PetalWidth
print("\nR√©sum√© de 'petalwidth' :")
print(df['petalwidth'].describe())

plt.figure(figsize=(8, 5))
plt.hist(df['petalwidth'], bins=10, edgecolor='black')
plt.title("Histogramme de la largeur du p√©tale")
plt.xlabel("Largeur du p√©tale (cm)")
plt.ylabel("Effectif")
plt.savefig('ex2_petal_width.png')
plt.show()

print("\n‚úÖ Exercice 2 termin√©")

# ========== EXERCICE 3 : NUAGE DE POINTS (√âTUDE BIVARI√âE) ==========
print("\n" + "="*60)
print("EXERCICE 3 : NUAGE DE POINTS ET CORR√âLATIONS")
print("="*60)

# 1- Repr√©sentation graphique des nuages de points pour chaque paire de variables
plt.figure(figsize=(12, 10))
sns.pairplot(df, hue='species')
plt.suptitle("Nuage de points des paires de variables", y=1.02)
plt.savefig('ex3_pairplot.png')
plt.show()

print("\n‚úÖ Exercice 3 termin√© - Les nuages de points montrent une bonne s√©paration par esp√®ce")

# ========== EXERCICE 4 : BOXPLOT (VARIABLE QUALITATIVE ET QUANTITATIVE) ==========
print("\n" + "="*60)
print("EXERCICE 4 : BOXPLOT PAR ESP√àCE")
print("="*60)

# 1) Longueur du p√©tale selon l'esp√®ce
plt.figure(figsize=(10, 6))
df.boxplot(column="petallength", by="species")
plt.title("Longueur du p√©tale selon l'esp√®ce")
plt.suptitle("")
plt.xlabel("Esp√®ce")
plt.ylabel("Longueur du p√©tale (cm)")
plt.savefig('ex4_boxplot_petal_length.png')
plt.show()

# 2) Autre variable : largeur du p√©tale selon l'esp√®ce
plt.figure(figsize=(10, 6))
df.boxplot(column="petalwidth", by="species")
plt.title("Largeur du p√©tale selon l'esp√®ce")
plt.suptitle("")
plt.xlabel("Esp√®ce")
plt.ylabel("Largeur du p√©tale (cm)")
plt.savefig('ex4_boxplot_petal_width.png')
plt.show()

print("\n‚úÖ Exercice 4 termin√© - Les boxplots confirment les diff√©rences entre esp√®ces")

# ========== EXERCICE 5 : INT√âGRATION DE L'ESP√àCE DANS L'ANALYSE ==========
print("\n" + "="*60)
print("EXERCICE 5 : CORR√âLATIONS ET VISUALISATIONS AVANC√âES")
print("="*60)

# 2) Corr√©lations entre variables quantitatives
correlation = df.drop("species", axis=1).corr()
print("\nMatrice de corr√©lation :")
print(correlation)

# Heatmap de corr√©lation
plt.figure(figsize=(10, 8))
sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)
plt.title("Matrice de corr√©lation des variables")
plt.savefig('ex5_correlation_heatmap.png')
plt.show()

# Nuage de points p√©tales avec distinction par esp√®ce
plt.figure(figsize=(10, 6))
for esp in df['species'].unique():
    sous_df = df[df['species'] == esp]
    plt.scatter(
        sous_df['petallength'],
        sous_df['petalwidth'],
        label=esp,
        s=50,
        alpha=0.7
    )

plt.title("Nuage de points p√©tales avec distinction par esp√®ce")
plt.xlabel("Longueur du p√©tale (cm)")
plt.ylabel("Largeur du p√©tale (cm)")
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('ex5_scatter_petales.png')
plt.show()

print("\n‚úÖ Exercice 5 termin√©")

# ========== √âTAPE 3 : PR√âPARATION DES DONN√âES ==========
print("\n" + "="*60)
print("√âTAPE 3 : PR√âPARATION DES DONN√âES POUR LE MACHINE LEARNING")
print("="*60)

# S√©parer caract√©ristiques (X) et cible (y)
X = df.drop('species', axis=1)
y = df['species']

print(f"\nDimensions X (caract√©ristiques) : {X.shape}")
print(f"Dimensions y (cible) : {y.shape}")
print(f"Classes : {y.unique()}")

# Division train/test (80%/20%)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nTaille ensemble d'entra√Ænement : {len(X_train)}")
print(f"Taille ensemble de test : {len(X_test)}")

# Normalisation des caract√©ristiques
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\n‚úÖ Normalisation effectu√©e avec StandardScaler")

# ========== √âTAPE 4 : CR√âATION ET ENTRA√éNEMENT DU MOD√àLE KNN ==========
print("\n" + "="*60)
print("√âTAPE 4 : ENTRA√éNEMENT DU MOD√àLE K-NEAREST NEIGHBORS")
print("="*60)

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_scaled, y_train)
print("\n‚úÖ Mod√®le KNN entra√Æn√© avec k=3")

# ========== √âTAPE 5 : √âVALUATION DU MOD√àLE ==========
print("\n" + "="*60)
print("√âTAPE 5 : √âVALUATION DU MOD√àLE KNN")
print("="*60)

# Pr√©dictions
y_pred = knn.predict(X_test_scaled)

# Exactitude
accuracy = accuracy_score(y_test, y_pred)
print(f"\nüéØ Exactitude du mod√®le KNN : {accuracy * 100:.2f}%")

# Rapport de classification
print("\nüìä Rapport de classification :")
print(classification_report(y_test, y_pred))

# Matrice de confusion
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', 
            xticklabels=df['species'].unique(), 
            yticklabels=df['species'].unique())
plt.title('Matrice de confusion - KNN (k=3)')
plt.xlabel('Pr√©dictions')
plt.ylabel('Vraies classes')
plt.savefig('confusion_matrix_knn.png')
plt.show()

print("\n‚úÖ √âvaluation termin√©e - Matrice de confusion sauvegard√©e")

# ========== √âTAPE 6 : INTERPR√âTATION DES R√âSULTATS ==========
print("\n" + "="*60)
print("√âTAPE 6 : INTERPR√âTATION DES R√âSULTATS")
print("="*60)

print("\nüìù Analyse de la matrice de confusion :")
print(f"   - Nombre total de pr√©dictions : {len(y_test)}")
print(f"   - Nombre de pr√©dictions correctes : {np.sum(y_pred == y_test)}")
print(f"   - Nombre d'erreurs : {np.sum(y_pred != y_test)}")

if np.sum(y_pred != y_test) > 0:
    print("\n   Erreurs d√©tect√©es dans les pr√©dictions.")
    print("   La normalisation a permis de mettre toutes les variables sur la m√™me √©chelle,")
    print("   ce qui am√©liore les performances du mod√®le KNN bas√© sur les distances.")
else:
    print("\n   ‚úÖ Aucune erreur - Performance parfaite !")

# ========== √âTAPE 7 : OPTIMISATION DES HYPER-PARAM√àTRES ==========
print("\n" + "="*60)
print("√âTAPE 7.1 : OPTIMISATION DES HYPER-PARAM√àTRES KNN")
print("="*60)

# Grid Search pour KNN
param_grid_knn = {
    'n_neighbors': [1, 3, 5, 7, 9, 11, 15, 20],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

print("\nRecherche des meilleurs hyper-param√®tres...")
print("Param√®tres test√©s :")
print(f"  - Nombre de voisins (k) : {param_grid_knn['n_neighbors']}")
print(f"  - Distances : {param_grid_knn['metric']}")

grid_search_knn = GridSearchCV(
    KNeighborsClassifier(), 
    param_grid_knn, 
    cv=5, 
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search_knn.fit(X_train_scaled, y_train)

print(f"\nüèÜ Meilleurs param√®tres KNN : {grid_search_knn.best_params_}")
print(f"üìà Meilleur score (validation crois√©e) : {grid_search_knn.best_score_:.4f}")

# Mod√®le optimis√©
best_knn = grid_search_knn.best_estimator_
y_pred_best = best_knn.predict(X_test_scaled)
accuracy_best = accuracy_score(y_test, y_pred_best)
print(f"üéØ Exactitude sur test (KNN optimis√©) : {accuracy_best * 100:.2f}%")

# ========== √âTAPE 7.2 : COMPARAISON AVEC D'AUTRES MOD√àLES ==========
print("\n" + "="*60)
print("√âTAPE 7.2 : COMPARAISON AVEC D'AUTRES MOD√àLES")
print("="*60)

models = {
    'KNN': KNeighborsClassifier(n_neighbors=3),
    'Logistic Regression': LogisticRegression(max_iter=200, random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Naive Bayes': GaussianNB(),
    'SVM': SVC(random_state=42),
    'Neural Network': MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)
}

results = {}

print("\nEntra√Ænement et √©valuation de 6 mod√®les diff√©rents...\n")

for name, model in models.items():
    # Entra√Ænement
    model.fit(X_train_scaled, y_train)
    
    # Pr√©dictions
    y_pred = model.predict(X_test_scaled)
    
    # Exactitude
    acc = accuracy_score(y_test, y_pred)
    
    # Validation crois√©e
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
    
    results[name] = {
        'accuracy': acc,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std()
    }
    
    print(f"{'='*50}")
    print(f"{name}:")
    print(f"  Exactitude test : {acc * 100:.2f}%")
    print(f"  CV moyenne : {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

# Visualisation des r√©sultats
print("\n" + "="*60)
print("VISUALISATION DES PERFORMANCES")
print("="*60)

model_names = list(results.keys())
accuracies = [results[m]['accuracy'] for m in model_names]

plt.figure(figsize=(12, 6))
bars = plt.bar(model_names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen', 'gold', 'orange', 'pink'])
plt.title('Comparaison des performances des mod√®les', fontsize=14, fontweight='bold')
plt.xlabel('Mod√®les')
plt.ylabel('Exactitude')
plt.ylim([0.85, 1.0])
plt.xticks(rotation=45, ha='right')

# Ajouter les valeurs sur les barres
for i, (bar, acc) in enumerate(zip(bars, accuracies)):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
             f'{acc:.2%}', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.savefig('models_comparison.png', dpi=300)
plt.show()

# Meilleur mod√®le
best_model_name = max(results, key=lambda x: results[x]['accuracy'])
print(f"\nüèÜ MEILLEUR MOD√àLE : {best_model_name}")
print(f"   Exactitude : {results[best_model_name]['accuracy'] * 100:.2f}%")
print(f"   CV moyenne : {results[best_model_name]['cv_mean']:.4f}")

# ========== SAUVEGARDE DU MEILLEUR MOD√àLE ==========
print("\n" + "="*60)
print("SAUVEGARDE DU MOD√àLE POUR D√âPLOIEMENT")
print("="*60)

# Sauvegarder le meilleur mod√®le et le scaler
best_model = models[best_model_name]
best_model.fit(X_train_scaled, y_train)

with open('best_model.pkl', 'wb') as f:
    pickle.dump(best_model, f)

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print("\n‚úÖ Fichiers sauvegard√©s :")
print("   - best_model.pkl (mod√®le entra√Æn√©)")
print("   - scaler.pkl (normalisation)")
print("\nüí° Ces fichiers peuvent √™tre utilis√©s pour le d√©ploiement avec Flask et Streamlit")

# ========== R√âSUM√â FINAL ==========
print("\n" + "="*60)
print("üéâ TP TERMIN√â AVEC SUCC√àS !")
print("="*60)

print("\nüìä R√âSUM√â DES √âTAPES R√âALIS√âES :")
print("   ‚úÖ Exercice 1 : Visualisation des effectifs par esp√®ce")
print("   ‚úÖ Exercice 2 : Analyse des variables quantitatives")
print("   ‚úÖ Exercice 3 : Nuages de points et corr√©lations")
print("   ‚úÖ Exercice 4 : Boxplots par esp√®ce")
print("   ‚úÖ Exercice 5 : Corr√©lations et visualisations avanc√©es")
print("   ‚úÖ √âtape 3 : Pr√©paration des donn√©es")
print("   ‚úÖ √âtape 4 : Entra√Ænement du mod√®le KNN")
print("   ‚úÖ √âtape 5 : √âvaluation du mod√®le")
print("   ‚úÖ √âtape 6 : Interpr√©tation des r√©sultats")
print("   ‚úÖ √âtape 7.1 : Optimisation des hyper-param√®tres")
print("   ‚úÖ √âtape 7.2 : Comparaison avec 6 mod√®les diff√©rents")
print("   ‚úÖ Sauvegarde des mod√®les pour d√©ploiement")

print("\nüöÄ PROCHAINES √âTAPES :")
print("   1. D√©ploiement avec Flask (API REST)")
print("   2. Interface Streamlit (Dashboard interactif)")
print("   3. Publication sur GitHub et Streamlit Cloud")

print("\n" + "="*60)
print("Merci d'avoir suivi ce TP ! üå∏")
print("="*60)
